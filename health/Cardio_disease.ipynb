{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d6ded-d7ed-4dea-811f-e982c9ed18dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiovascular Disease Status Report:\n",
      "       cardio Cardiovascular Disease Status\n",
      "0           0     No Cardiovascular Disease\n",
      "1           1        Cardiovascular Disease\n",
      "2           1        Cardiovascular Disease\n",
      "3           1        Cardiovascular Disease\n",
      "4           0     No Cardiovascular Disease\n",
      "...       ...                           ...\n",
      "69995       0     No Cardiovascular Disease\n",
      "69996       1        Cardiovascular Disease\n",
      "69997       1        Cardiovascular Disease\n",
      "69998       1        Cardiovascular Disease\n",
      "69999       0     No Cardiovascular Disease\n",
      "\n",
      "[70000 rows x 2 columns]\n",
      "\n",
      "Report saved to 'cardiovascular_disease_status_report.csv'.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nandh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6704 - loss: 0.6155 - val_accuracy: 0.7284 - val_loss: 0.5593\n",
      "Epoch 2/20\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7340 - loss: 0.5533 - val_accuracy: 0.7271 - val_loss: 0.5568\n",
      "Epoch 3/20\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7305 - loss: 0.5501 - val_accuracy: 0.7284 - val_loss: 0.5524\n",
      "Epoch 4/20\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7345 - loss: 0.5463 - val_accuracy: 0.7296 - val_loss: 0.5528\n",
      "Epoch 5/20\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7310 - loss: 0.5487 - val_accuracy: 0.7271 - val_loss: 0.5520\n",
      "Epoch 6/20\n",
      "\u001b[1m  5/875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7615 - loss: 0.5132  "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('cardio_train.csv', delimiter=';')\n",
    "\n",
    "# Drop 'id' column if present\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop('id', axis=1)\n",
    "\n",
    "# Create a new column for Cardiovascular Disease Status\n",
    "df['Cardiovascular Disease Status'] = df['cardio'].map({1: 'Cardiovascular Disease', 0: 'No Cardiovascular Disease'})\n",
    "\n",
    "# Generate the report\n",
    "cardio_report = df[['cardio', 'Cardiovascular Disease Status']]\n",
    "\n",
    "# Print the report\n",
    "print(\"Cardiovascular Disease Status Report:\")\n",
    "print(cardio_report)\n",
    "\n",
    "# Save the report to a CSV file\n",
    "cardio_report.to_csv('cardiovascular_disease_status_report.csv', index=False)\n",
    "print(\"\\nReport saved to 'cardiovascular_disease_status_report.csv'.\")\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(['cardio', 'Cardiovascular Disease Status'], axis=1).values\n",
    "y = df['cardio'].values\n",
    "\n",
    "# Split dataset with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions from Random Forest\n",
    "rf_train_pred = rf_model.predict(X_train_scaled)\n",
    "rf_test_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# RNN (using LSTM)\n",
    "X_train_rnn = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_rnn = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(1, X_train_scaled.shape[1]), return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "rnn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Add early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train RNN model\n",
    "history = rnn_model.fit(\n",
    "    X_train_rnn, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test_rnn, y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Generate predictions from RNN\n",
    "rnn_train_pred = (rnn_model.predict(X_train_rnn) > 0.5).astype(int).flatten()\n",
    "rnn_test_pred = (rnn_model.predict(X_test_rnn) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Create stacked dataset\n",
    "stacked_train = np.column_stack((rf_train_pred, rnn_train_pred))\n",
    "stacked_test = np.column_stack((rf_test_pred, rnn_test_pred))\n",
    "\n",
    "# Stacking model (Logistic Regression)\n",
    "stack_model = LogisticRegression(\n",
    "    C=0.1,\n",
    "    solver='liblinear',\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "stack_model.fit(stacked_train, y_train)\n",
    "\n",
    "# Final predictions\n",
    "final_pred = stack_model.predict(stacked_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, final_pred):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, final_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, final_pred))\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('RNN Training History')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix Visualization\n",
    "cm = confusion_matrix(y_test, final_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = ['No Cardiovascular Disease', 'Cardiovascular Disease']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
