{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce820a2-3c7c-4781-b5d0-84ccb25644e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('kidney_disease.csv')\n",
    "\n",
    "# Clean column names (remove spaces)\n",
    "\n",
    "# Convert target to binary and handle missing values\n",
    "df['classification'] = df['classification'].map({'ckd': 1, 'notckd': 0})\n",
    "\n",
    "# Drop rows where the target is NaN\n",
    "df = df.dropna(subset=['classification'])\n",
    "\n",
    "# Handle string values in numeric columns\n",
    "df.replace({'normal': 0, 'abnormal': 1, 'present': 1, 'notpresent': 0, \n",
    "            'yes': 1, 'no': 0, '\\tno': 0, '\\tyes': 1, 'good': 0, 'poor': 1}, inplace=True)\n",
    "\n",
    "# Convert object columns to numeric where possible\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Create a new column for Kidney Disease Status\n",
    "df['Kidney Disease Status'] = df['classification'].map({1: 'Chronic Kidney Disease', 0: 'No Kidney Disease'})\n",
    "\n",
    "# Generate the report\n",
    "kidney_report = df[['classification', 'Kidney Disease Status']]\n",
    "\n",
    "# Print the report\n",
    "print(\"Kidney Disease Status Report:\")\n",
    "print(kidney_report)\n",
    "\n",
    "# Save the report to a CSV file\n",
    "kidney_report.to_csv('kidney_disease_status_report.csv', index=False)\n",
    "print(\"\\nReport saved to 'kidney_disease_status_report.csv'.\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(['classification', 'Kidney Disease Status'], axis=1)\n",
    "y = df['classification'].values\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Use OneHotEncoder for categorical columns\n",
    "])\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Reshape for Conv1D (samples, features, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build improved CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=1),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(128, kernel_size=2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=1),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'AUC']\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy, auc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
